{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類のアーキテクチャ\n",
    "\n",
    "現在でもほとんどの最先端のアーキテクチャの基礎となっている以下のCNNアーキテクチャを見ていきます。\n",
    "\n",
    "- AlexNet\n",
    "- VGG\n",
    "- GoogleNet\n",
    "- ResNet\n",
    "- DenseNet\n",
    "\n",
    "今回からモデルが重くなるため、GoogleColabで実行します。  \n",
    "(前回まではMPSを使用していたのですが、今回のPytorch Lightningのコード内で解決できないバグがあるようですので、ColabのCuda環境で実行しています)  \n",
    "以下のボタンをクリックすると、GoogleColabに勝手に移動します。  \n",
    "リンクは、``https://github.com/``を``https://colab.research.google.com/github``に変更したURLにするだけです。\n",
    "```\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshida-chem/Intro2DL/blob/main/docs/07_image_arch/img_arch.ipynb)\n",
    "```\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yoshida-chem/Intro2DL/blob/main/docs/07_image_arch/img_arch.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "try:\n",
    "    import japanize_matplotlib\n",
    "except ModuleNotFoundError:\n",
    "    !pip install japanize_matplotlib\n",
    "    import japanize_matplotlib\n",
    "import numpy as np \n",
    "import time\n",
    "import copy\n",
    "import requests\n",
    "from PIL import Image\n",
    "from types import SimpleNamespace\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        # GPUありの場合\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    # PytorchLightningでエラーが出るので、MPSはパス\n",
    "    #elif torch.backends.mps.is_built():\n",
    "    #    device = torch.device(\"mps:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviceはmps:0です\n"
     ]
    }
   ],
   "source": [
    "# pytorchでデータをダウンロードするときのパス（重複してDWしないため）\n",
    "DATASET_PATH = \"../data\"\n",
    "# モデルの保存先\n",
    "CHECKPOINT_PATH = \"../models/07_image_arch\"\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# 再現性のためにseedを固定する\n",
    "set_seed(42)\n",
    "\n",
    "# device情報を取得する\n",
    "device = get_device()\n",
    "print(f\"deviceは{device}です\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "\n",
    "今回は、CIFAR10のデータセットを使用します。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Data mean [0.49139968 0.48215841 0.44653091]\n",
      "Data std [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "# 正規化のための統計値を計算\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0,1,2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0,1,2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 正規化＋FlipとResizeCropのデータ拡張\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "                                     ])\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "                                     ])\n",
    "\n",
    "# datasetの準備\n",
    "# validationではデータ拡張なし\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
    "\n",
    "# 訓練データとバリデーションデータに分割（ここで、同じ分割＆バリデーション時はデータ拡張なし）\n",
    "set_seed(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "set_seed(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "# dataloaderの準備\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "Batch mean tensor([0.0231, 0.0006, 0.0005])\n",
      "Batch std tensor([0.9865, 0.9849, 0.9868])\n"
     ]
    }
   ],
   "source": [
    "# チャネルごとに正規化できているか確認\n",
    "imgs, _ = next(iter(train_loader))\n",
    "\n",
    "# BatchSize, Channel, W, Hの形状を持つ\n",
    "print(imgs.shape)\n",
    "print(\"Batch mean\", imgs.mean(dim=[0,2,3]))\n",
    "print(\"Batch std\", imgs.std(dim=[0,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_IMAGES = 4\n",
    "images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
    "# transformする場合は、Image Typeに変換する必要あり\n",
    "orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
    "orig_images = [train_transform(img) for img in orig_images]\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Augmentation examples on CIFAR10\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アーキテクチャの実装\n",
    "\n",
    "準備として活性化関数がまとまった辞書を作っておきます。これは後述のPytorch Lightningでハイパーパラメータを保存したいためです。（Objectを引数にすると保存されない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leakyrelu\": nn.LeakyReLU,\n",
    "    \"gelu\": nn.GELU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "AlexNetは、画像認識のコンテストILSVRC 2012で優勝したモデルです。AlexNetは５つの畳み込み層と３つのプーリング層、２つのコントラスト正規化、３つの全結合層により構成されています。学習では、fc6とfc7の層のユニットにドロップアウト(p=0.5)が用いられています。また、各CNN層とFC層の後にはReLUが使用されています。また、Local Response Normを第一と第二のCNN層の後のReLUの後に適応しています。これは汎化性能を上げたようですが、現在のBatch Normalizationが開発前なためこちらが使われているようです。\n",
    "\n",
    "また、元論文では当時のGPUの性能からブロックを２つに分けているので、今回は１つにまとめます。\n",
    "詳しくは、元論文の3.5 Overall Architectureを参考にしてください。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/alexnet.png\" alt=\"AlexNet\" title=\"AlexNet\">\n",
    "\n",
    "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, act_fn_name=\"relu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.hparams.name でアクセスしたいので、SimpleNamespaceを使用\n",
    "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
    "                                       act_fn_name=act_fn_name,\n",
    "                                       act_fn=act_fn_by_name[act_fn_name])\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_network(self):\n",
    "        self.features = nn.Sequential(\n",
    "            # 1st layer\n",
    "            ## channel48*2をまとめてchannel=96にしている。また、WとHのサイズを合わせるためにpadding=2へ変更\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2),\n",
    "            self.hparams.act_fn(),\n",
    "            ## ハイパーパラメータは元論文中でバリデーションを元に決められています\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 3-5rd layer\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=256*6*6, out_features=4096),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=self.hparams.num_classes),\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # 元論文とは異なる初期化\n",
    "        # 活性化関数に基づきConv2dの初期化を行う\n",
    "        # ResNetではmode=\"fan_out\"出力側で計算を選択されているが、ここではデフォルトのfan_inを選択\n",
    "        # https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L156 \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity=self.hparams.act_fn_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 96, 55, 55])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 実装中のサイズの確認\n",
    "# N * C * W * H\n",
    "tmp = torch.rand(1, 3, 224, 224)\n",
    "print(tmp.shape)\n",
    "\n",
    "cnn = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2)\n",
    "tmp_ = cnn(tmp)\n",
    "print(tmp_.shape)\n",
    "\n",
    "net = AlexNet(num_classes=10, act_fn_name=\"relu\")\n",
    "tmp_ = net(tmp)\n",
    "print(tmp_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n",
    "\n",
    "VGGは、ILSVRC2014で提案されたモデルで、16層または19層からなるCNNを使用したモデルになります。  \n",
    "VGGNetはAlexNetを大規模にしたもので、3*3のフィルタを使用することで活性化関数の適用回数が増え表現力が増加しています。AlexNetと比較するとコントラスト正規化層がなくなっています。\n",
    "\n",
    "欠点としては、Global Average Pooling層がないため、全結合層の箇所のパラメータが多くなり計算が重い点です。\n",
    "今回は、下記画像のDであるVGG16を実装しました。VGG19は後半３つのCNN層が１つずつ多くなる点が異なります。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/vggnet.png\" alt=\"VGGNet\" title=\"VGGNet\">\n",
    "\n",
    "https://arxiv.org/pdf/1409.1556.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, act_fn_name=\"relu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.hparams.name でアクセスしたいので、SimpleNamespaceを使用\n",
    "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
    "                                       act_fn_name=act_fn_name,\n",
    "                                       act_fn=act_fn_by_name[act_fn_name])\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_network(self):\n",
    "        self.features = nn.Sequential(\n",
    "            # 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            # 4\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            # 5\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=512*7*7, out_features=4096),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            self.hparams.act_fn(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=self.hparams.num_classes),\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # 元論文とは異なる初期化\n",
    "        # 活性化関数に基づきConv2dの初期化を行う\n",
    "        # ResNetではmode=\"fan_out\"出力側で計算を選択されているが、ここではデフォルトのfan_inを選択\n",
    "        # https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L156 \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity=self.hparams.act_fn_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 実装中のサイズの確認\n",
    "# N * C * W * H\n",
    "tmp = torch.rand(1, 3, 224, 224)\n",
    "print(tmp.shape)\n",
    "\n",
    "net = VGG16Net(num_classes=10, act_fn_name=\"relu\")\n",
    "tmp_ = net(tmp)\n",
    "print(tmp_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n",
    "\n",
    "VGGがILSVRC2014で二位を獲得した際の優勝したモデルであるGoogleNetを実装します。\n",
    "Inception Blockとglobal average pooling(GAP)が特徴的なアーキテクチャです。\n",
    "\n",
    "#### Inception Block\n",
    "\n",
    "Inceptionブロックは、同じ特徴マップに対して、1x1、3x3、5x5のCNNと、Max Poolingという4つのブロックを別々に適用します。これにより、ネットワークは同じデータを異なる受容野で見ることができます。また、実装では1x1のCNN(ボトルネック層やPointwise Convolutionとも呼ばれているCNN層)を挟むことで、まずチャンネル方向の畳込みを行った後に縦横方向の畳込みを行うことができ、分割して計算をすることになるため演算量を削減できています。もちろん、5x5の畳み込みだけを学習する方が理論的には強力ですが、これはより計算とメモリが重いだけでなく、オーバーフィットしやすくなる傾向があります。  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/Inception.png\" alt=\"Inception\" title=\"Inception\">\n",
    "\n",
    "全体のインセプションブロックは以下のように実装できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_red : dict, c_out : dict, act_fn):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input feature maps from the previous layers\n",
    "            c_red - Dictionary with keys \"3x3\" and \"5x5\" specifying the output of the dimensionality reducing 1x1 convolutions\n",
    "            c_out - Dictionary with keys \"1x1\", \"3x3\", \"5x5\", and \"max\"\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1x1 convolution branch\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out[\"1x1\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"1x1\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        # 3x3 convolution branch\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"3x3\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"3x3\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"3x3\"], c_out[\"3x3\"], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(c_out[\"3x3\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        # 5x5 convolution branch\n",
    "        self.conv_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"5x5\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"5x5\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"5x5\"], c_out[\"5x5\"], kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(c_out[\"5x5\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        # Max-pool branch\n",
    "        self.max_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(c_in, c_out[\"max\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"max\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1x1 = self.conv_1x1(x)\n",
    "        x_3x3 = self.conv_3x3(x)\n",
    "        x_5x5 = self.conv_5x5(x)\n",
    "        x_max = self.max_pool(x)\n",
    "        # 連結\n",
    "        x_out = torch.cat([x_1x1, x_3x3, x_5x5, x_max], dim=1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のInception Blockを用いてGoogleNetを実装します。元論文では以下のようなかなり大きなモデルですが、今回はMNISTの簡単な問題を解きたいだけなので縮小して実装されています。また、Batch Normalizationはこの後のResNetで提案されたものですが、今回の実装ではGoogleNetにも使用されている点も注意してください。\n",
    "\n",
    "#### Global Average Pooling（GAP） \n",
    "GAPは、各チャンネルの値の平均を算出することでパラメータ数を削減します。各チャネルごとの平均により、過学習を抑制することが期待できます。また、出力されたニューロンの数がチャネル数飲みに依存するので、入力の画像サイズに依存しなくなるという特徴もあります。  \n",
    "ResNetでも使用されている方法ですが、Pytorchで直接実装されていないので``nn.AdaptiveAvgPool2d((1,1))``として使用する必要があります。https://www.テクめも.com/entry/pytorch-pooling\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/GoogleNet.png\" alt=\"googlenet\" title=\"googlenet\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, act_fn_name=\"relu\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
    "                                       act_fn_name=act_fn_name,\n",
    "                                       act_fn=act_fn_by_name[act_fn_name])\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "\n",
    "    def _create_network(self):\n",
    "        # チャネルサイズを上げる\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            self.hparams.act_fn()\n",
    "        )\n",
    "        # Inception Blocks\n",
    "        self.inception_blocks = nn.Sequential(\n",
    "            InceptionBlock(64, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 32, \"5x5\": 8, \"max\": 8}, act_fn=self.hparams.act_fn),\n",
    "            InceptionBlock(64, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12}, act_fn=self.hparams.act_fn),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # 32x32 => 16x16\n",
    "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12}, act_fn=self.hparams.act_fn),\n",
    "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
    "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
    "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 48, \"5x5\": 24, \"max\": 24}, act_fn=self.hparams.act_fn),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # 16x16 => 8x8\n",
    "            InceptionBlock(128, c_red={\"3x3\": 48, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
    "            InceptionBlock(128, c_red={\"3x3\": 48, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn)\n",
    "        )\n",
    "        # 出力\n",
    "        self.output_net = nn.Sequential(\n",
    "            # Linearで繋げる場合はC*W*Hのサイズが必要だったが、GAPがあることでチャネル数C=128のみになり計算量削減\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, self.hparams.num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # 活性化関数に基づき初期化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, nonlinearity=self.hparams.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.inception_blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 実装中のサイズの確認\n",
    "# N * C * W * H\n",
    "tmp = torch.rand(1, 3, 224, 224)\n",
    "print(tmp.shape)\n",
    "\n",
    "net = GoogleNet(num_classes=10, act_fn_name=\"relu\")\n",
    "tmp_ = net(tmp)\n",
    "print(tmp_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "#### 残差接続\n",
    "\n",
    "残差接続では、$x_{l+1} = F(x_l)$をモデル化する代わりに、$x_{l+1} = x_l + F(x_l)$をモデル化します。ここで、$F()$は非線形関数です。このような残差接続に対して勾配を計算すると、以下のようになり$F$の影響を受けにくく安定した勾配伝播が可能になります。実装上の注意点としては、$x_l$と$F(x_l)$を足し算する必要があるので、$F()$で解像度を下げた場合は特徴マップの形状が同じになるように変換が必要である点です。\n",
    "\n",
    "$$\n",
    "\\partial x_{l+1}/\\partial x_l = I + \\partial F(x_l)/\\partial x_l \n",
    "$$\n",
    "\n",
    "ResNetにはいくつかのバージョンが提案されているので、ここでは3つ見ていきます。\n",
    "\n",
    "- Original ResNet block：スキップコネクションの後にReLUを適用する。元論文の実装。\n",
    "- Pre-Activation ResNet block：Fの初めの段階でReLUを適用する。より深いネットワークでは上記のように勾配流が恒等行列を持つことを保証できるため、こちらの方が良いことが知られています。(下図; https://arxiv.org/abs/1603.05027)\n",
    "- BottleNeckを持つResNet block：計算量を増やすことなくブロック内のチャネル数を増やす狙い。Inception Block同様に計算量を削減するために1x1のCNNが使用されている。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/residual-block.png\" alt=\"resblock\" title=\"resblock\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - Trueの場合、関数F内でstride=2にすることで解像度を下げる。Falseの場合そのまま。\n",
    "            c_out - subsample=Trueの場合のみ、有効。Falseの場合、入力と同じ。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "            \n",
    "        # 上記の説明における関数F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),  # No bias needed as the Batch Norm handles it\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "        \n",
    "        # 1x1 convolution with stride 2 により、元の入力のサイズを下げる \n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # F(x)\n",
    "        z = self.net(x)\n",
    "        # x : stride=2で解像度下がる場合、形状を同じにする\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        # skip connection\n",
    "        out = x + z\n",
    "        # skip connectionの後にReLUがくる\n",
    "        out = self.act_fn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - Trueの場合、関数F内でstride=2にすることで解像度を下げる。Falseの場合そのまま。\n",
    "            c_out - subsample=Trueの場合のみ、有効。Falseの場合、入力と同じ。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "            \n",
    "        # 上記の説明における関数F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            # skip connection の最初の段階でReLUを適用\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "        \n",
    "        # 1*1 CNNを適用する場合は非線形性を適用する必要あり \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, stride=2, bias=False)\n",
    "        ) if subsample else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # F(x)\n",
    "        z = self.net(x)\n",
    "        # x : stride=2で解像度下がる場合、形状を同じにする\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        # skip connection\n",
    "        out = x + z\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeckResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - Trueの場合、関数F内でstride=2にすることで解像度を下げる。Falseの場合そのまま。\n",
    "            c_out - Number of output features.論文中では、c_out = c_in*4 とされています\n",
    "            https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "            \n",
    "        # 上記の説明における関数F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_in, kernel_size=1, padding=1, stride=1 if not subsample else 2, bias=False),  # No bias needed as the Batch Norm handles it\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_in, kernel_size=3, padding=1),  # No bias needed as the Batch Norm handles it\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "        \n",
    "        # 1x1 convolution with stride 2 により、元の入力のサイズを下げる\n",
    "        # また、BottleNeckタイプは最後のチャネル数が２５６になったりするので変更 \n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=1 if not subsample else 2)\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # F(x)\n",
    "        z = self.net(x)\n",
    "        # x : stride=2で解像度下がる場合、形状を同じにする\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        # skip connection\n",
    "        out = x + z\n",
    "        # skip connectionの後にReLUがくる\n",
    "        out = self.act_fn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_blocks_by_name = {\n",
    "    \"ResNetBlock\": OriginalResNetBlock,\n",
    "    \"PreActResNetBlock\": PreActResNetBlock,\n",
    "    \"BottleNeckResNetBlock\": BottleNeckResNetBlock\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet全体のアーキテクチャは、複数のResNetブロックを積み重ねることで構成されており、そのうちのいくつかは入力をダウンサンプリングしています。ネットワーク全体のResNetブロックについて話すとき通常、同じ出力形状でグループ化します。つまり、ResNetが[3,3,3]のブロックを持つということは、3つのResNetブロックのグループを3回重ね、4番目と7番目のブロックでサブサンプリングが行われていることを意味しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, num_blocks=[3,3,3], c_hidden=[16,32,64], act_fn_name=\"relu\", block_name=\"ResNetBlock\", **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            num_classes - Number of classification outputs (10 for CIFAR10)\n",
    "            num_blocks - List with the number of ResNet blocks to use. The first block of each group uses downsampling, except the first.\n",
    "            c_hidden - List with the hidden dimensionalities in the different blocks. Usually multiplied by 2 the deeper we go.\n",
    "            act_fn_name - Name of the activation function to use, looked up in \"act_fn_by_name\"\n",
    "            block_name - Name of the ResNet block, looked up in \"resnet_blocks_by_name\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert block_name in resnet_blocks_by_name\n",
    "        self.hparams = SimpleNamespace(num_classes=num_classes, \n",
    "                                       c_hidden=c_hidden, \n",
    "                                       num_blocks=num_blocks, \n",
    "                                       act_fn_name=act_fn_name,\n",
    "                                       act_fn=act_fn_by_name[act_fn_name],\n",
    "                                       block_class=resnet_blocks_by_name[block_name])\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "\n",
    "    def _create_network(self):\n",
    "        c_hidden = self.hparams.c_hidden\n",
    "        \n",
    "        # A first convolution on the original image to scale up the channel size\n",
    "        if self.hparams.block_class == PreActResNetBlock: # => Don't apply non-linearity on output\n",
    "            self.input_net = nn.Sequential(\n",
    "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False)\n",
    "            )\n",
    "        else:\n",
    "            self.input_net = nn.Sequential(\n",
    "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(c_hidden[0]),\n",
    "                self.hparams.act_fn()\n",
    "            )\n",
    "        \n",
    "        # Creating the ResNet blocks\n",
    "        blocks = []\n",
    "        for block_idx, block_count in enumerate(self.hparams.num_blocks):\n",
    "            for bc in range(block_count):\n",
    "                subsample = (bc == 0 and block_idx > 0) # Subsample the first block of each group, except the very first one.\n",
    "                blocks.append(\n",
    "                    self.hparams.block_class(c_in=c_hidden[block_idx if not subsample else (block_idx-1)],\n",
    "                                             act_fn=self.hparams.act_fn,\n",
    "                                             subsample=subsample,\n",
    "                                             c_out=c_hidden[block_idx])\n",
    "                )\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        # Mapping to classification output\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(c_hidden[-1], self.hparams.num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
    "        # Fan-out focuses on the gradient distribution, and is commonly used in ResNets\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.hparams.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet\n",
    "\n",
    "DenseNetは、ResNetとは少し異なる方法でskip connectionを用いることで冗長な特徴マップを学習する必要性を排除しています。  \n",
    "ネットワークに深く入り込むと、モデルはパターンを認識するために抽象的な特徴を学習します。しかし、複雑なパターンの中には、抽象的な特徴（手、顔など）と低レベルの特徴（エッジ、基本色など）の組み合わせで構成されているものがあるため、このような低レベルの特徴を深い層で見つけるためには、再度学習しなければならず無駄になります。  \n",
    "DenseNetは、以下の図のように各畳み込みが以前のすべての入力特徴マップを少量のフィルターを増やす(増やすフィルターの数$k$は、成長率パラメータ(Growth rate)と呼ばれています)だけでに、特徴を再利用することができる効率的な方法になります。(https://arxiv.org/pdf/1608.06993.pdf)   \n",
    "また、一番最後の層はTransition Layerと呼ばれる層で、特徴マップの高さ、幅、チャンネルの大きさの次元を減らす役割を担っています。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/denseblock.png\" alt=\"denseblock\" title=\"denseblock\">\n",
    "\n",
    "実装としては、DenseBlockとDenseBlockを構成するDenseLayer、DenseBlockの一番最後の層であるTransition Layerで構成されます。\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yoshida-chem/Intro2DL/main/docs/07_image_arch/densenet.png\" alt=\"densenet\" title=\"densenet\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, bn_size, growth_rate, act_fn):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input channels\n",
    "            bn_size - Bottleneck size (factor of growth rate) for the output of the 1x1 convolution. Typically between 2 and 4.\n",
    "            growth_rate - Number of output channels of the 3x3 convolution\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, bn_size * growth_rate, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(bn_size * growth_rate),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        # 出力チャネルは入力のオリジナルと連結される\n",
    "        out = torch.cat([out, x], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, num_layers, bn_size, growth_rate, act_fn):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input channels\n",
    "            num_layers - Number of dense layers to apply in the block\n",
    "            bn_size - Bottleneck size to use in the dense layers\n",
    "            growth_rate - Growth rate to use in the dense layers\n",
    "            act_fn - Activation function to use in the dense layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for layer_idx in range(num_layers):\n",
    "            layers.append(\n",
    "                # 以前の全ての層の特徴マップを連結した元の入力を入力とする\n",
    "                # 出力は：c_out = c_in + layer_idx * growth_rate + growth_rateになる \n",
    "                DenseLayer(c_in=c_in + layer_idx * growth_rate, \n",
    "                           bn_size=bn_size,\n",
    "                           growth_rate=growth_rate,\n",
    "                           act_fn=act_fn)\n",
    "            )\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out, act_fn):\n",
    "        super().__init__()\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            # 1*1 CNNでチャネル方向の次元削減\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, bias=False),\n",
    "            # 高さと幅を削減するために、カーネルサイズ2とストライド2の平均プーリングを適用する\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2) # Average the output for each 2x2 pixel group\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.transition(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を使用してDenseNetを構築していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10, num_layers=[6,6,6,6], bn_size=2, growth_rate=16, act_fn_name=\"relu\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
    "                                       num_layers=num_layers,\n",
    "                                       bn_size=bn_size,\n",
    "                                       growth_rate=growth_rate,\n",
    "                                       act_fn_name=act_fn_name,\n",
    "                                       act_fn=act_fn_by_name[act_fn_name])\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "        \n",
    "    def _create_network(self):\n",
    "        c_hidden = self.hparams.growth_rate * self.hparams.bn_size # The start number of hidden channels\n",
    "        \n",
    "        # A first convolution on the original image to scale up the channel size\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, c_hidden, kernel_size=3, padding=1) # No batch norm or activation function as done inside the Dense layers\n",
    "        )\n",
    "        \n",
    "        # Creating the dense blocks, eventually including transition layers\n",
    "        blocks = []\n",
    "        for block_idx, num_layers in enumerate(self.hparams.num_layers):\n",
    "            blocks.append( \n",
    "                DenseBlock(c_in=c_hidden, \n",
    "                           num_layers=num_layers, \n",
    "                           bn_size=self.hparams.bn_size,\n",
    "                           growth_rate=self.hparams.growth_rate,\n",
    "                           act_fn=self.hparams.act_fn)\n",
    "            )\n",
    "            # denseblockの出力 = c_in + blockの層の数 * growth_rate\n",
    "            c_hidden = c_hidden + num_layers * self.hparams.growth_rate \n",
    "            if block_idx < len(self.hparams.num_layers)-1: # Don't apply transition layer on last block\n",
    "                blocks.append(\n",
    "                    TransitionLayer(c_in=c_hidden,\n",
    "                                    c_out=c_hidden // 2,\n",
    "                                    act_fn=self.hparams.act_fn))\n",
    "                c_hidden = c_hidden // 2\n",
    "                \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        # Mapping to classification output\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_hidden), # The features have not passed a non-linearity until here.\n",
    "            self.hparams.act_fn(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(c_hidden, self.hparams.num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning\n",
    "\n",
    "Pytorch Lightningを使用することで、細かいコードを書かなくても良くなるのでより本質的な作業に時間を費やすことができるようになります。\n",
    "例えば、``to_device``を書かなくてもいいので、その分実装も楽です。\n",
    "\n",
    "ここでは、``pl.LightningModule（torch.nn.Moduleを継承）``を継承します。このクラスは5つの主要なメソッドを持ちます。もしこれら以外のコードを変更する場合は、overwriteできる関数があるので、ドキュメントを参照します。  \n",
    "\n",
    "- 初期化(__init__): 必要なパラメータやモデルを作成します\n",
    "- オプティマイザ(configure_optimizers): オプティマイザ、学習率スケジューラなどを作成します\n",
    "- トレーニングループ(training_step)：単一バッチの損失計算を定義するだけ（optimizer.zero_grad(), loss.backward() および optimizer.step() のループ。ログ記録/保存操作はバックグラウンドで行われます）。\n",
    "- 検証ループ(validation_step) 訓練と同様に、ステップごとに何が起こるかを定義するだけです\n",
    "- テストループ(test_step): 検証と同じで、テストセットに対してのみ行われます\n",
    "\n",
    "参考：https://qiita.com/ground0state/items/c1d705ca2ee329cdfae4   \n",
    "参考：https://tech.jxpress.net/entry/2021/11/17/112214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "  import pytorch_lightning as pl\n",
    "except ModuleNotFoundError:\n",
    "  !pip install pytorch_lightning\n",
    "  import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, MetricCollection\n",
    "\n",
    "# pytorch lightningでは以下のコードでSeedを固定できます\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"AlexNet\": AlexNet,\n",
    "    \"VGG16Net\": VGG16Net,\n",
    "    \"GoogleNet\": GoogleNet,\n",
    "    \"ResNet\": ResNet,\n",
    "    \"DenseNet\": DenseNet\n",
    "}\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = create_model(model_name, model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "        self.train_metrics = MetricCollection([Accuracy(), Precision(), Recall(), F1Score()], prefix='train_')\n",
    "        self.val_metrics = MetricCollection([Accuracy(), Precision(), Recall(), F1Score()], prefix='val_')\n",
    "        self.test_metrics = MetricCollection([Accuracy(), Precision(), Recall(), F1Score()], prefix='test_')\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(\n",
    "                self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[100, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        #acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        #self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
    "        #preds_for_metrics = preds.argmax(dim=-1)\n",
    "        #self.train_metrics(preds_for_metrics, labels)\n",
    "        #self.log_dict(self.train_metrics, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss  # Return tensor to call \".backward\" on\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        preds_for_metrics = preds.argmax(dim=-1)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        self.log('val_loss', loss)\n",
    "        #acc = (labels == preds_for_metrics).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches)\n",
    "        #self.log('val_acc', acc)\n",
    "        #self.val_metrics(preds_for_metrics, labels)\n",
    "        #self.log_dict(self.val_metrics)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        self.log('test_loss', loss)\n",
    "\n",
    "        #preds_for_metrics = self.model(imgs).argmax(dim=-1)\n",
    "        #self.test_metrics(preds_for_metrics, labels)\n",
    "        #self.log_dict(self.test_metrics)\n",
    "        #acc = (labels == preds_for_metrics).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        #self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "        \n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    if str(device) == \"mps:0\":\n",
    "        trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
    "                         accelerator=\"mps\" if str(device)==\"mps:0\" else \"cpu\",\n",
    "                         devices=1 if str(device)==\"mps:0\" else 0,                                           # We run on a single GPU (if possible)\n",
    "                         max_epochs=30,                                                                     # How many epochs to train for if no patience is set\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "                                    LearningRateMonitor(\"epoch\"),                                            # Log Learning raate every epoch\n",
    "                                    EarlyStopping(monitor=\"val_loss\", mode=\"min\")],                          # early stopping\n",
    "                         enable_progress_bar=True)    \n",
    "    else:\n",
    "        trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
    "                         gpus=1 if str(device)==\"cuda:0\" else 0,\n",
    "                         devices=1,                                        # We run on a single GPU (if possible)\n",
    "                         max_epochs=30,                                                                     # How many epochs to train for if no patience is set\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "                                    LearningRateMonitor(\"epoch\"),                                            # Log Learning raate every epoch\n",
    "                                    EarlyStopping(monitor=\"val_loss\", mode=\"min\")],                          # early stopping\n",
    "                         enable_progress_bar=True)   \n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    \n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = CIFARModule(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "        \n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "    \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/yyamaguchi/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name          | Type             | Params | In sizes       | Out sizes\n",
      "--------------------------------------------------------------------------------\n",
      "0 | model         | GoogleNet        | 260 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module   | CrossEntropyLoss | 0      | ?              | ?        \n",
      "2 | train_metrics | MetricCollection | 0      | ?              | ?        \n",
      "3 | val_metrics   | MetricCollection | 0      | ?              | ?        \n",
      "4 | test_metrics  | MetricCollection | 0      | ?              | ?        \n",
      "--------------------------------------------------------------------------------\n",
      "260 K     Trainable params\n",
      "0         Non-trainable params\n",
      "260 K     Total params\n",
      "1.043     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613e07d33e214490bc46834bce1136f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b67d12010a4e59a98ae7275e7ac876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yyamaguchi/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル41 を /Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m googlenet_model, googlenet_results \u001b[39m=\u001b[39m train_model(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mGoogleNet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                  model_hparams\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mnum_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m10\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                                 \u001b[39m\"\u001b[39;49m\u001b[39mact_fn_name\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m}, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                  optimizer_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                  optimizer_hparams\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                                                     \u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1e-4\u001b[39;49m})\n",
      "\u001b[1;32mセル41 を /Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, save_name, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     model \u001b[39m=\u001b[39m CIFARModule(model_name\u001b[39m=\u001b[39mmodel_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     trainer\u001b[39m.\u001b[39mfit(model, train_loader, val_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     model \u001b[39m=\u001b[39m CIFARModule\u001b[39m.\u001b[39;49mload_from_checkpoint(trainer\u001b[39m.\u001b[39;49mcheckpoint_callback\u001b[39m.\u001b[39;49mbest_model_path) \u001b[39m# Load best checkpoint after training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Test best model on validation and test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch/img_arch.ipynb#X24sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m val_result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtest(model, val_loader, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[1;32m     66\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[1;32m    138\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    139\u001b[0m         checkpoint_path,\n\u001b[1;32m    140\u001b[0m         map_location,\n\u001b[1;32m    141\u001b[0m         hparams_file,\n\u001b[1;32m    142\u001b[0m         strict,\n\u001b[1;32m    143\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     map_location \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m storage, loc: storage\n\u001b[1;32m    183\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 184\u001b[0m     checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m hparams_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     extension \u001b[39m=\u001b[39m hparams_file\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:46\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\u001b[39mstr\u001b[39m(path_or_url), map_location\u001b[39m=\u001b[39mmap_location)\n\u001b[1;32m     45\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 46\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/fsspec/spec.py:1034\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1034\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1035\u001b[0m         path,\n\u001b[1;32m   1036\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1037\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1038\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1039\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1040\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1041\u001b[0m     )\n\u001b[1;32m   1042\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/fsspec/implementations/local.py:162\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/fsspec/implementations/local.py:260\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 260\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/Desktop/programming/Intro2DL/.venv/lib/python3.9/site-packages/fsspec/implementations/local.py:265\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    266\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    267\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/Users/yyamaguchi/Desktop/programming/Intro2DL/docs/07_image_arch'"
     ]
    }
   ],
   "source": [
    "googlenet_model, googlenet_results = train_model(model_name=\"GoogleNet\", \n",
    "                                                 model_hparams={\"num_classes\": 10, \n",
    "                                                                \"act_fn_name\": \"relu\"}, \n",
    "                                                 optimizer_name=\"Adam\",\n",
    "                                                 optimizer_hparams={\"lr\": 1e-3,\n",
    "                                                                    \"weight_decay\": 1e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8af3c9a3e8d4af82748b103937dc9dd31fe9c46ee50d6fcc9d6d272118d69b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
