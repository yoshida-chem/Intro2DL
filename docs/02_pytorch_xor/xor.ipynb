{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例題：XOR\n",
    "\n",
    "PytorchにおけるNNの学習/推論を行うにあたり、XORの例題を使用します。  \n",
    "XORとは、$x_1$と$x_2$の片方が1で残りが0であればラベル１、それら以外のケースであればラベル0を入力するような問題で、単純な線形関数ではうまく推論できないです。\n",
    "\n",
    "この例題を解くために、Pytorchのモジュールを使用していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築の流れ\n",
    "\n",
    "基本的には以下の流れで実行します。\n",
    "\n",
    "1. モデルの定義\n",
    "2. DataLoaderの準備\n",
    "3. lossやoptimizerなどの準備  \n",
    "~ここから学習開始~\n",
    "4. DataLoaderからバッチの取得\n",
    "5. バッチをモデルへ入力し予測値を得る\n",
    "6. 予測値と実測値からLossを計算する\n",
    "7. ロスに関して各パラメータの勾配を計算する\n",
    "8. 勾配方向へモデルのパラメータを更新する\n",
    "9. 3~7の操作をイタレーションの回数行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. モデルの定義\n",
    "\n",
    "XORの例題から、入力は$x_1$と$x_2$の２変数で、ラベルは$0$と$1$のみです。  \n",
    "また、モデルは活性化関数がtanh, 隠れ層を１つだけ持つネットワークを考えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchのモデルは以下のような構成である必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # xを入力とした時の計算\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_in, num_hid)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.layer2 = nn.Linear(num_hid, num_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (layer1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (layer2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時、モデルが持つパラメータを見てみます。``Tanh``はパラメータを持たないので、layerのパラメータのみ表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter layer1.weight, shape torch.Size([4, 2])\n",
      "Parameter layer1.bias, shape torch.Size([4])\n",
      "Parameter layer2.weight, shape torch.Size([1, 4])\n",
      "Parameter layer2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意点としては、layerの定義の仕方です。``self.?``のような形で定義しないと以下のように認識/登録されないです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier()\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        layer1 = nn.Linear(num_in, num_hid)\n",
    "        act_fn = nn.Tanh()\n",
    "        layer2 = nn.Linear(num_hid, num_out)\n",
    "        self.list_layer = [layer1, act_fn, layer2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.list_layer:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように定義したい場合は、``nn.ModuleList``や``nn.ModuleDict``, ``nn.Sequential``を使用します。ここでは、``nn.ModuleList``の例のみを見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (list_layer): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Parameter list_layer.0.weight, shape torch.Size([4, 2])\n",
      "Parameter list_layer.0.bias, shape torch.Size([4])\n",
      "Parameter list_layer.2.weight, shape torch.Size([1, 4])\n",
      "Parameter list_layer.2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        layer1 = nn.Linear(num_in, num_hid)\n",
    "        act_fn = nn.Tanh()\n",
    "        layer2 = nn.Linear(num_hid, num_out)\n",
    "        self.list_layer = nn.ModuleList([layer1, act_fn, layer2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.list_layer:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. DataLoaderの準備\n",
    "\n",
    "pytorchでデータを扱う際は、``Dataset``と``DataLoader``を使用します。  \n",
    "シンプルには、``Dataset``はi番目のデータを取得するためのクラスで、``DataLoader``はバッチ処理などを効率的に実装できるクラスです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataを効率的に扱うモジュールをインポート\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Dataset``クラスはi番目のデータを返す``__getitem__()``とデータのサイズを返す``__len__()``を持ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "(tensor([ 0.9450, -0.0377]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=2500)\n",
    "print(dataset.size)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``DataLoader``クラスは上記で定義した``Dataset``の``__getitem__``を使用して、バッチ処理などをよしなに実行してくれます。\n",
    "\n",
    "オプションは以下の通りです。\n",
    "- batch_size: バッチサイズを指定します\n",
    "- shuffle: データセットの並び順をシャッフルするかどうか\n",
    "- pin_memory: GPU上のメモリにデータをコピーします。サイズが大きい時には有効ですが、GPUのメモリを消費するので単なる検証や推論の時には必要ないです。\n",
    "- drop_last: batch_sizeでデータの数を割り切れない時の余りを使用するかどうか（訓練時のみバッチサイズを一定に保つために必要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x108bbde20>\n",
      "Data inputs torch.Size([128, 2]) \n",
      " tensor([[-7.2804e-02,  1.1041e+00],\n",
      "        [ 1.1450e+00,  1.7077e-02],\n",
      "        [ 4.0985e-02, -5.4373e-02],\n",
      "        [ 7.5966e-02,  9.7802e-01],\n",
      "        [ 2.2727e-02,  8.9922e-01],\n",
      "        [ 1.2303e-01,  1.0085e+00],\n",
      "        [-7.5358e-02,  7.5478e-02],\n",
      "        [ 1.0237e+00,  1.1585e+00],\n",
      "        [ 1.0081e+00, -6.0899e-02],\n",
      "        [ 1.0971e+00,  8.7675e-01],\n",
      "        [ 1.2261e+00,  1.0328e+00],\n",
      "        [-3.4534e-02,  8.2188e-01],\n",
      "        [-1.6522e-02,  9.7790e-01],\n",
      "        [ 9.6733e-01,  1.0362e+00],\n",
      "        [ 1.0112e-01,  8.8916e-01],\n",
      "        [-5.9085e-02,  8.7525e-01],\n",
      "        [ 2.0926e-02,  1.0810e-01],\n",
      "        [ 1.6433e-02, -9.2412e-03],\n",
      "        [ 1.0063e+00,  9.2770e-01],\n",
      "        [ 2.3867e-02,  9.4516e-01],\n",
      "        [ 9.3029e-01,  1.0644e+00],\n",
      "        [ 1.0317e+00, -5.0927e-04],\n",
      "        [-7.4040e-02,  1.1017e+00],\n",
      "        [-5.3543e-04,  2.0390e-02],\n",
      "        [ 7.6709e-02,  9.2210e-01],\n",
      "        [ 1.9267e-02,  1.0064e-01],\n",
      "        [-1.4015e-01,  7.9226e-01],\n",
      "        [ 2.3145e-01,  9.9505e-01],\n",
      "        [ 9.6408e-01,  4.8191e-02],\n",
      "        [ 6.9211e-02, -7.1338e-02],\n",
      "        [ 3.2373e-02,  1.0113e+00],\n",
      "        [ 1.2508e+00,  8.0529e-02],\n",
      "        [ 1.0965e+00, -1.4765e-01],\n",
      "        [-4.0061e-02, -5.2052e-02],\n",
      "        [-2.0837e-01,  8.3516e-01],\n",
      "        [ 1.0791e+00, -7.4755e-02],\n",
      "        [ 7.9891e-01,  2.0973e-01],\n",
      "        [ 9.0706e-01,  7.6696e-01],\n",
      "        [ 9.1724e-01,  9.1130e-01],\n",
      "        [ 1.1240e+00, -2.8604e-02],\n",
      "        [-1.5656e-01, -6.1603e-02],\n",
      "        [ 3.9071e-02,  1.0703e+00],\n",
      "        [ 1.1136e-01,  7.6418e-02],\n",
      "        [-4.0319e-02,  9.1122e-01],\n",
      "        [-1.2613e-01,  9.2346e-01],\n",
      "        [ 8.6311e-01,  4.1220e-03],\n",
      "        [-1.7388e-01,  1.1669e-01],\n",
      "        [-7.4471e-02, -1.9813e-01],\n",
      "        [ 1.0433e+00,  1.0701e+00],\n",
      "        [ 1.2681e-01,  1.0351e+00],\n",
      "        [-7.1518e-02, -2.9065e-01],\n",
      "        [-3.2377e-02,  1.0505e+00],\n",
      "        [-2.6789e-01,  1.2169e-01],\n",
      "        [ 1.8959e-01, -1.2496e-01],\n",
      "        [ 2.9532e-02,  1.2342e-01],\n",
      "        [ 8.3225e-01, -9.2726e-02],\n",
      "        [ 9.6130e-01,  1.0646e+00],\n",
      "        [ 9.1031e-01,  9.7370e-01],\n",
      "        [ 1.0166e+00,  1.0392e+00],\n",
      "        [ 2.0528e-01, -1.2846e-02],\n",
      "        [ 1.0167e+00,  9.3552e-01],\n",
      "        [ 8.8396e-01,  9.7615e-01],\n",
      "        [ 1.0432e+00,  1.0095e+00],\n",
      "        [ 9.9360e-01,  1.0981e+00],\n",
      "        [ 1.3962e-03,  1.0370e+00],\n",
      "        [ 3.1574e-02,  7.6176e-03],\n",
      "        [ 1.1352e+00,  1.0465e+00],\n",
      "        [ 8.2953e-03, -9.6899e-02],\n",
      "        [ 1.0000e+00,  3.2121e-02],\n",
      "        [ 9.7082e-02,  8.8162e-01],\n",
      "        [ 5.3385e-02,  1.0033e-01],\n",
      "        [ 9.5098e-01,  1.3654e-02],\n",
      "        [ 6.9419e-02,  1.0831e+00],\n",
      "        [ 1.0508e+00,  1.0540e+00],\n",
      "        [ 2.6655e-02,  8.9375e-01],\n",
      "        [-1.0887e-01,  2.2077e-02],\n",
      "        [ 8.7785e-01,  9.4118e-01],\n",
      "        [-4.8292e-03, -1.5647e-01],\n",
      "        [ 7.2836e-01,  6.2586e-02],\n",
      "        [-6.3113e-03,  2.2185e-02],\n",
      "        [-1.3274e-01,  8.6549e-01],\n",
      "        [ 1.0961e+00,  1.0224e+00],\n",
      "        [ 1.0638e+00,  1.5344e-02],\n",
      "        [-9.7978e-02,  1.6069e-01],\n",
      "        [ 1.0346e+00,  1.1706e+00],\n",
      "        [ 1.2919e-01, -8.1029e-02],\n",
      "        [ 1.0119e+00,  9.2153e-01],\n",
      "        [-2.8104e-02, -2.3104e-02],\n",
      "        [ 1.1002e-01,  1.0594e+00],\n",
      "        [ 2.3332e-01, -8.6315e-02],\n",
      "        [ 1.4667e-01,  9.6280e-01],\n",
      "        [ 1.1106e+00,  8.0643e-01],\n",
      "        [ 1.2023e-01,  1.0180e+00],\n",
      "        [-6.0721e-02,  1.1322e+00],\n",
      "        [ 8.6859e-01,  9.8454e-01],\n",
      "        [ 1.0771e-01, -8.9369e-02],\n",
      "        [ 4.4324e-02,  1.0185e+00],\n",
      "        [-8.9303e-02,  9.8590e-01],\n",
      "        [ 9.6519e-01,  1.0608e+00],\n",
      "        [ 9.3951e-01, -5.4688e-02],\n",
      "        [ 2.2585e-02,  9.2614e-01],\n",
      "        [-7.6468e-02,  2.1452e-01],\n",
      "        [ 7.2733e-02, -7.3930e-02],\n",
      "        [ 1.1124e+00,  1.1067e+00],\n",
      "        [ 2.8434e-01, -9.9704e-02],\n",
      "        [ 1.0294e+00, -1.8035e-01],\n",
      "        [-2.8473e-02,  9.1512e-01],\n",
      "        [ 1.9851e-01,  1.5367e-03],\n",
      "        [ 1.1980e-01,  8.8696e-01],\n",
      "        [ 2.0547e-01,  1.0220e+00],\n",
      "        [-1.9407e-01,  8.4612e-01],\n",
      "        [-1.5697e-01, -1.0190e-01],\n",
      "        [-8.0814e-02,  1.1973e-01],\n",
      "        [ 1.0253e+00,  9.5834e-01],\n",
      "        [ 1.0403e+00,  1.0607e+00],\n",
      "        [ 9.2056e-01,  6.0310e-02],\n",
      "        [ 9.5124e-01,  1.2482e+00],\n",
      "        [-2.2171e-02,  9.7395e-02],\n",
      "        [-2.3042e-01,  3.6538e-02],\n",
      "        [ 8.7662e-02,  9.6314e-01],\n",
      "        [ 6.3132e-03,  7.1874e-02],\n",
      "        [ 1.6658e-01,  1.4259e-01],\n",
      "        [ 9.4618e-01,  8.5934e-01],\n",
      "        [ 1.1190e+00,  9.6802e-01],\n",
      "        [ 7.7979e-02,  9.1017e-01],\n",
      "        [ 1.0036e+00,  1.1159e+00],\n",
      "        [ 1.0358e+00,  9.7519e-01],\n",
      "        [ 2.8420e-02, -3.8281e-02]])\n",
      "Data labels torch.Size([128]) \n",
      " tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "print(data_loader)\n",
    "\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. lossやoptimizerなどの準備\n",
    "\n",
    "**Lossの定義**\n",
    "\n",
    "今回は２値分類なので、Binary Cross Entropy (BCE)ロスを使用します。pytorchではBCE lossは``nn.BCELoss()``と``nn.BCEWithLogitsLoss()``の２種類あります。``nn.BCEWithLogitsLoss()``はSigmoidの層とBCE lossが１つのクラスになったもので、１つに結合することでlog-sum-exp trickにより数値的に安定します。そのため、今回はモデルの定義のところではSigmoidの層を抜きにして、ロスに``nn.BCEWithLogitsLoss()`を使用します。\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**otimizzerの定義**\n",
    "\n",
    "様々な最適化手法がありますが、今回は確率的勾配降下法（Stochastic Gradient Descent; SGD）を使用します。勾配の更新レベルを決める学習率を指定する必要がありますが、今回の小さなネットワークには0.1を設定します。\n",
    "\n",
    "optimizerは``.step()``と``.zero_grad()``という関数を持ちます。``.step()``関数は計算された勾配情報を元にパラメータを更新します。``.zero_grad()``関数はすべてのパラメータの勾配情報を０にします。これがなぜ必要なのかというと、勾配情報は計算されるたびに前回計算された値に加算されていくためです。そのため、``.backward()``の前に必ず``.zero_grad()``を行う必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここで、modelのパラメータを入力します\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**モデルをGPUへ移す**\n",
    "\n",
    "データをGPUにPushします。ここで、モデルは１回きり行えば大丈夫です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (list_layer): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-9. 学習\n",
    "\n",
    "学習では以下のSTEPを行います。  \n",
    "\n",
    "4. DataLoaderからバッチの取得 \n",
    "5. バッチをモデルへ入力し予測値を得る \n",
    "6. 予測値と実測値からLossを計算する \n",
    "7. ロスに関して各パラメータの勾配を計算する \n",
    "8. 勾配方向へモデルのパラメータを更新する \n",
    "9. 3~7の操作をイタレーションの回数行う\n",
    "\n",
    "訓練中は``model.train()``によりモデルをtrainのmodeにします。これは、``dropout``や``BatchNorm``などが学習時と推論時で挙動が異なるためです。推論時は``model.eval()``を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_module, data_loader, num_epochs=100):\n",
    "    # modelをtrain modeに設定する\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 4. ここからbatch処理が走る\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            # dataをdeviceに移す\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "\n",
    "            # 5. バッチをモデルへ入力し予測値を得る \n",
    "            preds = model(data_inputs)\n",
    "            # [Batch size, 1] -> [Batch size]へ変換\n",
    "            preds = preds.squeeze(dim=1) \n",
    "\n",
    "            # 6. Lossを計算する\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "            # 7. 勾配を計算する\n",
    "            # 必ず勾配計算前にzero_grad()を実行する\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "\n",
    "            ## 8. 勾配情報をもとにパラメータを更新する\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 158.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, loss_module, data_loader, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの保存と読み込み\n",
    "\n",
    "``model.state_dict()``に学習可能なパラメータを取得できます。これを用いて、``torch.save()``により保存します。  \n",
    "また、``torch.load()``によりパラメータを読み込むことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('list_layer.0.weight', tensor([[ 2.5581,  2.6572],\n",
      "        [ 2.1702, -1.7598],\n",
      "        [ 2.0181, -2.4040],\n",
      "        [ 1.8723,  1.7103]])), ('list_layer.0.bias', tensor([-1.0644,  0.8969, -1.0651, -2.7404])), ('list_layer.2.weight', tensor([[ 3.7602, -2.7670,  2.9931, -3.2199]])), ('list_layer.2.bias', tensor([-0.6014]))])\n"
     ]
    }
   ],
   "source": [
    "# 学習可能なパラメータを取得\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "\n",
    "# 保存\n",
    "torch.save(state_dict, \"our_model.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上記で保存したファイルを取得\n",
    "state_dict = torch.load(\"our_model.tar\")\n",
    "\n",
    "# modelを作成し、パラメータを読み込む\n",
    "new_model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "new_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論\n",
    "\n",
    "推論時は、計算グラフ/勾配を作成/計算する必要もないため、メモリの削減と速度アップのために勾配計算をしません。計算グラフを構築しないためには、``with torch.no_grad():``を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XORDataset(size=500)\n",
    "# 推論時なので、shuffle=False, drop_last=Falseを指定しておきます\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    # 推論モードに設定\n",
    "    model.eval()\n",
    "\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    # これ以降は計算グラフを作成しない\n",
    "    with torch.no_grad():\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            # 推論\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            # sigmoidにより0~1の間に変換する\n",
    "            preds = torch.sigmoid(preds)\n",
    "            # 0か１へ変換する\n",
    "            pred_labels = (preds >= 0.5).long()\n",
    "            \n",
    "            # Accuracyの計算\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "            \n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# 今回は非常に簡単なデータなので、Acc.＝１００になっています\n",
    "eval_model(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で例題は終わりです。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8af3c9a3e8d4af82748b103937dc9dd31fe9c46ee50d6fcc9d6d272118d69b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
