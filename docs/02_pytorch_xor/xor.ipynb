{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例題：XOR\n",
    "\n",
    "PytorchにおけるNNの学習/推論を行うにあたり、XORの例題を使用します。  \n",
    "XORとは、$x_1$と$x_2$の片方が1で残りが0であればラベル１、それら以外のケースであればラベル0を入力するような問題で、単純な線形関数ではうまく推論できないです。\n",
    "\n",
    "この例題を解くために、Pytorchのモジュールを使用していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築の流れ\n",
    "\n",
    "基本的には以下の流れで実行します。\n",
    "\n",
    "1. モデルの定義\n",
    "2. DataLoaderの準備\n",
    "3. lossやoptimizerなどの準備  \n",
    "~ここから最適化開始~\n",
    "4. DataLoaderからバッチの取得\n",
    "5. バッチをモデルへ入力し予測値を得る\n",
    "6. 予測値と実測値からLossを計算する\n",
    "7. ロスに関して各パラメータの勾配を計算する\n",
    "8. 勾配方向へモデルのパラメータを更新する\n",
    "9. 3~7の操作をイタレーションの回数行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. モデルの定義\n",
    "\n",
    "XORの例題から、入力は$x_1$と$x_2$の２変数で、ラベルは$0$と$1$のみです。  \n",
    "また、モデルは活性化関数がtanh, 隠れ層を１つだけ持つネットワークを考えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchのモデルは以下のような構成である必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # xを入力とした時の計算\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_in, num_hid)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.layer2 = nn.Linear(num_hid, num_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (layer1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (layer2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時、モデルが持つパラメータを見てみます。``Tanh``はパラメータを持たないので、layerのパラメータのみ表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter layer1.weight, shape torch.Size([4, 2])\n",
      "Parameter layer1.bias, shape torch.Size([4])\n",
      "Parameter layer2.weight, shape torch.Size([1, 4])\n",
      "Parameter layer2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意点としては、layerの定義の仕方です。``self.?``のような形で定義しないと以下のように認識/登録されないです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier()\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        layer1 = nn.Linear(num_in, num_hid)\n",
    "        act_fn = nn.Tanh()\n",
    "        layer2 = nn.Linear(num_hid, num_out)\n",
    "        self.list_layer = [layer1, act_fn, layer2]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.list_layer:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように定義したい場合は、``nn.ModuleList``や``nn.ModuleDict``, ``nn.Sequential``を使用します。ここでは、``nn.ModuleList``の例のみを見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (list_layer): ModuleList(\n",
      "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Parameter list_layer.0.weight, shape torch.Size([4, 2])\n",
      "Parameter list_layer.0.bias, shape torch.Size([4])\n",
      "Parameter list_layer.2.weight, shape torch.Size([1, 4])\n",
      "Parameter list_layer.2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_in, num_hid, num_out):\n",
    "        super().__init__()\n",
    "        layer1 = nn.Linear(num_in, num_hid)\n",
    "        act_fn = nn.Tanh()\n",
    "        layer2 = nn.Linear(num_hid, num_out)\n",
    "        self.list_layer = nn.ModuleList([layer1, act_fn, layer2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.list_layer:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleClassifier(num_in=2, num_hid=4, num_out=1)\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. DataLoaderの準備\n",
    "\n",
    "pytorchでデータを扱う際は、``Dataset``と``DataLoader``を使用します。  \n",
    "シンプルには、``Dataset``はi番目のデータを取得するためのクラスで、``DataLoader``はバッチ処理などを効率的に実装できるクラスです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataを効率的に扱うモジュールをインポート\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Dataset``クラスはi番目のデータを返す``__getitem__()``とデータのサイズを返す``__len__()``を持ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "(tensor([0.9210, 0.9966]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "dataset = XORDataset(size=200)\n",
    "print(dataset.size)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``DataLoader``クラスは上記で定義した``Dataset``の``__getitem__``を使用して、バッチ処理などをよしなに実行してくれます。\n",
    "\n",
    "オプションは以下の通りです。\n",
    "- batch_size: バッチサイズを指定します\n",
    "- shuffle: データセットの並び順をシャッフルするかどうか\n",
    "- pin_memory: GPU上のメモリにデータをコピーします。サイズが大きい時には有効ですが、GPUのメモリを消費するので単なる検証や推論の時には必要ないです。\n",
    "- drop_last: batch_sizeでデータの数を割り切れない時の余りを使用するかどうか（訓練時のみバッチサイズを一定に保つために必要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x16a9ac5b0>\n",
      "Data inputs torch.Size([8, 2]) \n",
      " tensor([[ 1.0277,  1.0672],\n",
      "        [-0.0125,  1.0780],\n",
      "        [ 0.8900,  0.0438],\n",
      "        [ 0.0583,  1.0024],\n",
      "        [-0.0013, -0.1857],\n",
      "        [-0.1804,  0.1562],\n",
      "        [ 1.1222,  0.8559],\n",
      "        [ 0.9104,  0.9939]])\n",
      "Data labels torch.Size([8]) \n",
      " tensor([0, 1, 1, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "print(data_loader)\n",
    "\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最適化\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8af3c9a3e8d4af82748b103937dc9dd31fe9c46ee50d6fcc9d6d272118d69b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
